{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d229c30c",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "It is a way to turn words into meaningful numbers. <br /> It stores how a word is used. It can capture things like which words appear near it, what it can replace, and what usually comes before or after it.\n",
    "\n",
    "cat is close to dog pet and animal. <br />\n",
    "food is close to drink, cook. <br /> <br />\n",
    "These embeddings are learned automatically. <br /> <br />\n",
    "\n",
    "`block_size` : How many tokens the model procress in one forward pass. <br />\n",
    "In the example below we are taking 15 data in a chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc457210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "data = string.printable\n",
    "\n",
    "def get_chunk(block_size, idx):\n",
    "    x = data[idx:idx + block_size]\n",
    "    y = data[idx + 1:idx + block_size + 1]\n",
    "    return x, y\n",
    "\n",
    "x, y = get_chunk(12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a338d8",
   "metadata": {},
   "source": [
    "### Input and expected output\n",
    "We have the above function cause we want to predict the next token in our character level model. So the code below gives the example of what we might expect as output `y` when our input is `x`. <br />\n",
    "<b>Character based model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26a38cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when the input is tensor([15]) output is 30\n",
      "when the input is tensor([15, 30]) output is 21\n",
      "when the input is tensor([15, 30, 21]) output is 21\n",
      "when the input is tensor([15, 30, 21, 21]) output is 74\n",
      "when the input is tensor([15, 30, 21, 21, 74]) output is 28\n",
      "when the input is tensor([15, 30, 21, 21, 74, 28]) output is 29\n",
      "when the input is tensor([15, 30, 21, 21, 74, 28, 29]) output is 10\n",
      "when the input is tensor([15, 30, 21, 21, 74, 28, 29, 10]) output is 12\n",
      "when the input is tensor([15, 30, 21, 21, 74, 28, 29, 10, 12]) output is 20\n",
      "when the input is tensor([15, 30, 21, 21, 74, 28, 29, 10, 12, 20]) output is 94\n"
     ]
    }
   ],
   "source": [
    "from src.tokenizer import Tokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = Tokenizer(data)\n",
    "\n",
    "phrase = torch.tensor(tokenizer.encode(\"full-stack application\"))\n",
    "\n",
    "block_size = 10\n",
    "\n",
    "for i in range(0, block_size):\n",
    "    input_arr = phrase[:i + 1]\n",
    "    print(f\"when the input is {input_arr} output is {phrase[i + 1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd65ca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(25, 128)\n",
      "Embedding(75, 128)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block_size = 25\n",
    "        self.d_model = 128\n",
    "        self.vocab_size = 75\n",
    "\n",
    "        self.p_e = nn.Embedding(self.block_size, self.d_model)\n",
    "        self.t_e = nn.Embedding(self.vocab_size, self.d_model)\n",
    "\n",
    "transformer = Transformer()\n",
    "print(transformer.p_e)\n",
    "print(transformer.t_e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
